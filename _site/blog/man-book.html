<!DOCTYPE html>


<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Shell Adventures: Compiling a Manpages Ebook | implicit.computer</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@artalar/mono/mono.css">
    <link rel="stylesheet" href="/assets/style.css">
</head>
<body>
    <header>
        <nav>
            <a href="/">Home</a>
            <a href="/blog/">Blog</a>
        </nav>
    </header>
    
    <main>
        <article>
    <h1>Shell Adventures: Compiling a Manpages Ebook</h1>
    <time datetime="2024-03-21"</time>
    
    <p><a href="https://en.wikipedia.org/wiki/Man_page">man pages</a> are truly the best software documentation out there, with famously zero problems with formatting, content, or navigability.</p>
<p>In fact, haven't we all at some point wished we could access the man pages in a form factor more suitable for cozy reading, so we might curl up by the fire with a mug of cocoa and the documentation for <code>xargs(1)</code>?  Good news, in this post you can join me as I figure out how to accomplish just that, by compiling the man pages on my own machine into an epub with nice formatting.</p>
<p>What's that, no one has ever wanted this and I'm just a very strange person? Well tough tapioca, I'm doing it anyway. This is <em>my</em> website and if you don't like it, you can just click <a href="https://en.wikipedia.org/wiki/Never_Gonna_Give_You_Up">here</a> to travel to a different web page.</p>
<h1>Part 1: Scraping and Converting</h1>
<p>I spent a fair bit of time working on the problem of getting the actual page contents, but only for the pages I actually would want to read.  I had some ideas for scraping the Debian package archive and using the <a href="https://popcon.debian.org/">Debian popularity contest</a> metrics to fetch only the most used packages' docs.</p>
<p>Then I realized, a bit emberrassed, that I was doing all this <em>on</em> a Debian machine that had all the software I considered essential, so all that scraping and sorting was moot. If I wanted to learn the details of a program enough to peruse all its docs, I would also have to have the actual program installed. <a href="https://www.youtube.com/watch?v=L_o_O7v1ews">The files are <em>inside</em> the computer!</a></p>
<p>So, the first step is to convert all the local man files to ...something. Probably some kind of XML eventually, but I'm hoping I won't need to manually figure that part out. For now, markdown is a decent choice.</p>
<p>Actually the <em>zeroth</em> step is collecting all the page files</p>
<pre><code class="language-bash">$ find /usr/share/man/man* -type f | sort | head -n 5

    /usr/share/man/man1/7z.1.gz
    /usr/share/man/man1/aa-enabled.1.gz
    /usr/share/man/man1/aa-exec.1.gz
    /usr/share/man/man1/aa-features-abi.1.gz
    /usr/share/man/man1/acorn.1.gz
</code></pre>
<p>The vast majority are gzip compressed, some are uncompressed, and a tiny handful are bzip2 compressed. Let's sort that out.</p>
<pre><code class="language-bash">function handle_decompress {
  local page=&quot;$1&quot;
  local extension=&quot;${page##*.}&quot;
  case &quot;$extension&quot; in
    gz)
      gzip -dc &quot;$page&quot;
      ;;

    bz2)
      bzip2 -dc &quot;$page&quot;
      ;;

    *)
      cat &quot;$page&quot;
      ;;
  esac
}

</code></pre>
<p>OK, now those of you who've been shouting &quot;PANDOC&quot; at your screen - well first of all, you're worrying your neighbors. But you were correct, that's where we're going.</p>
<pre><code class="language-bash">for page in $( find /usr/share/man/man* -type f); do
    handle_decompress $page | pandoc -f man -t markdown
done
</code></pre>
<p>This just prints the markdown to stdout so we can verify it's working. It does work, but it's pretty slow. With a small refactor we can use <a href="https://en.wikipedia.org/wiki/GNU_parallel">GNU parallel</a> to speed things up a lot.</p>
<pre><code class="language-bash">BOOK_PAGES=&quot;./book&quot;
export  BOOK_PAGES

# ..snip..
export -f handle_decompress

function process_manpage {
  
  local section_dir=&quot;$BOOK_PAGES/$(basename &quot;$(dirname $1 )&quot; )&quot;
  mkdir -p &quot;$section_dir&quot;

  local clean_filename=$(basename &quot;$1&quot; .gz)
  local output_file=&quot;$section_dir/$clean_filename.md&quot;

  handle_decompress &quot;$1&quot; | pandoc -f man -t markdown &gt; $output file
}

export -f process_manpage

for man_dir in /usr/share/man/man*; do
  find &quot;$man_dir&quot; -type f | parallel process_manpage {} 
done
</code></pre>
<p>I also made the outputs redirect to a specified directory while maintaining the original subdirectory structure. The <code>export -f</code> lines are needed to make the functions available in each <code>parallel</code> sub-process. Now we've got the pages, let's make the book!</p>
<h1>Part 2: Making the Book</h1>
<p>I was anticipating the process for this as more or less a pandoc -&gt; <a href="https://calibre-ebook.com/">calibre</a> pipeline, with pandoc for file conversion on the individual pages and calibre for the overall book structure. But it turns out pandoc can just <a href="https://pandoc.org/epub.html">output epub directly</a>. Markdown was a lucky choice for the initial conversion <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, since pandoc <em>loves</em> working with markdown. We can just supply a list of markdown files in the correct chapter order.</p>
<pre><code class="language-bash">pandoc $( find $BOOK_DIR  -type f | sort ) -o manpages.epub
</code></pre>
<p>It works! But the chapter divisions are all borked; each subheader within a page is counted as a new chapter. To fix this we can use <code>sed</code> to bump all the headers down by one level.</p>
<pre><code class="language-bash"># ...
  handle_decompress &quot;$1&quot; | pandoc -f man -t markdown  | sed 's/^\(#\+\)\s*\([^#]\+\)/#\1 \2/'&gt; $output file
#...
</code></pre>
<p>This just adds one extra '#' to all headers. So each page becomes a chapter, we can append the page's name as a <code>h1</code> header to the top</p>
<pre><code class="language-bash">
# ...
  echo &quot;$clean_filename&quot; | sed 's/\(.\+\).\([0-9]\)/# \1(\2)\n/' &gt;  &quot;$output_file&quot;

  handle_decompress &quot;$1&quot; | \
    pandoc -f man -t markdown  | \
    sed 's/^\(#\+\)\s*\([^#]\+\)/#\1 \2/' &gt;&gt; &quot;$output_file&quot;
# ...
</code></pre>
<p>.. and then generate a table of contents based on those inserted headers.</p>
<pre><code class="language-bash">pandoc $(find &quot;$BOOK_PAGES&quot; -type f | sort ) \
  --toc --toc-depth=1 \
  --metadata title=&quot;Man Pages&quot; \
  -o manpages.epub 
</code></pre>
<p>Voila! Here's the full script for completeness.</p>
<pre><code class="language-bash">#!/bin/bash

BOOK_PAGES=&quot;./book&quot;
export  BOOK_PAGES

# stop on error
set -eu

# print decompressed file contents to stdout
function handle_decompress {
  local page=&quot;$1&quot;
  local extension=&quot;${page##*.}&quot;
  case &quot;$extension&quot; in
    gz)
      gzip -dc &quot;$page&quot;
      ;;

    bz2)
      bzip2 -dc &quot;$page&quot;
      ;;

    *)
      cat &quot;$page&quot;
      ;;
  esac
}
export -f handle_decompress

function process_manpage {
  
  local section_dir=&quot;$BOOK_PAGES/$(basename &quot;$(dirname $1 )&quot; )&quot;
  mkdir -p &quot;$section_dir&quot;

  local clean_filename=$(basename &quot;$1&quot; .gz)
  local output_file=&quot;$section_dir/$clean_filename.md&quot;

  # make the header
  echo &quot;$clean_filename&quot; | sed 's/\(.\+\).\([0-9]\)/# \1(\2)\n/' &gt;  &quot;$output_file&quot;

  # decompress, transform, edit headers, and write to output file
  handle_decompress &quot;$1&quot; | \
    pandoc -f man -t markdown  | \
    sed 's/^\(#\+\)\s*\([^#]\+\)/#\1 \2/' &gt;&gt; &quot;$output_file&quot;
}

export -f process_manpage

for man_dir in /usr/share/man/man*; do
  find &quot;$man_dir&quot; -type f | parallel process_manpage {} 
done

# actually compile the pages into a book
pandoc $(find &quot;$BOOK_PAGES&quot; -type f | sort ) \
  --toc --toc-depth=1 \
  --metadata title=&quot;Man Pages&quot; \
  -o manpages.epub 
</code></pre>
<p>It works quite well! There's a few tweaks I might make in the future</p>
<ul>
<li>The chapters are ordered correctly by section, and alphabetically within each section (so all the <code>man 1</code> pages come before the <code>man 2</code> pages, etc), but there's no &quot;official&quot; subdivision based on section; if you want to view only the pages in section 8, you need to scroll past all of sections 1-7 in the table of contents. Probably I can change the regex for headers to make this work.</li>
<li>The actual compilation step takes a long time since it's not (easily) made parallel. I don't know a good solution to this that also keeps this project within the realm of &quot;easy breezy afternoon one-off&quot;. That said, it's Good Enough for me.</li>
</ul>
<hr>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Or it appears that way to you anyway, through the magic of &quot;writing the post after completing the project&quot; <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    
    
    <ul class="tags">
        
        <li><a href="/tags/shell/">shell</a></li>
        
        <li><a href="/tags/100DaysToOffload/">100DaysToOffload</a></li>
        
        <li><a href="/tags/linux/">linux</a></li>
        
        <li><a href="/tags/programming/">programming</a></li>
        
    </ul>
    


</article>

    </main>
</body>
</html>
